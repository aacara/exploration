{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "characteristic-intranet",
   "metadata": {},
   "source": [
    "# E10: 뉴스기사 요약해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-harvest",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-amplifier",
   "metadata": {},
   "source": [
    "- NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리\n",
    " - NLTK의 불용어(stopwords)를 사용\n",
    " - 이 NLTK에는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장\n",
    " - 의미를 분석하고 요약하는 데는 거의 의미가 없는 100여개의 불용어가 미리 정리되어 있다 \n",
    " - 이를 이용해 다운로드한 리뷰 파일에서 불용어를 제거하는 작업을 진행할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "blond-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39376</th>\n",
       "      <td>Pranab Mukherjee's daughter rubbishes reports ...</td>\n",
       "      <td>Former President Pranab Mukherjee's daughter a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47283</th>\n",
       "      <td>Moving clam served to diner at Japanese sushi ...</td>\n",
       "      <td>A customer at a Japanese eatery ate a sushi di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>Rohit Sharma 1st Indian to slam 5 ODI hundreds...</td>\n",
       "      <td>Opener Rohit Sharma has become the first India...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>K'taka Cong MLA injured in fight with another ...</td>\n",
       "      <td>Karnataka Congress MLA Anand Singh was hospita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89903</th>\n",
       "      <td>Supreme Court to adjudicate in Leander, Rhea P...</td>\n",
       "      <td>The Supreme Court has decided to intervene in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83315</th>\n",
       "      <td>Oracle, Getty support $1.2 billion fine agains...</td>\n",
       "      <td>Seven US companies including Oracle and Getty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60607</th>\n",
       "      <td>Auto driver molests 21-year-old girl in Bengaluru</td>\n",
       "      <td>A 21-year-old student was allegedly molested b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>TDP MLA out on bail slaps man over torn poster...</td>\n",
       "      <td>TDP MLA Chinthamaneni Prabhakar allegedly slap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49562</th>\n",
       "      <td>What a guy: Anushka on Kohli's ODI century in ...</td>\n",
       "      <td>Actress Anushka Sharma shared a series of pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63127</th>\n",
       "      <td>Rohit Sharma sets record for most sixes by an ...</td>\n",
       "      <td>Indian opener Rohit Sharma slammed four sixes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "39376  Pranab Mukherjee's daughter rubbishes reports ...   \n",
       "47283  Moving clam served to diner at Japanese sushi ...   \n",
       "2433   Rohit Sharma 1st Indian to slam 5 ODI hundreds...   \n",
       "1222   K'taka Cong MLA injured in fight with another ...   \n",
       "89903  Supreme Court to adjudicate in Leander, Rhea P...   \n",
       "83315  Oracle, Getty support $1.2 billion fine agains...   \n",
       "60607  Auto driver molests 21-year-old girl in Bengaluru   \n",
       "34997  TDP MLA out on bail slaps man over torn poster...   \n",
       "49562  What a guy: Anushka on Kohli's ODI century in ...   \n",
       "63127  Rohit Sharma sets record for most sixes by an ...   \n",
       "\n",
       "                                                    text  \n",
       "39376  Former President Pranab Mukherjee's daughter a...  \n",
       "47283  A customer at a Japanese eatery ate a sushi di...  \n",
       "2433   Opener Rohit Sharma has become the first India...  \n",
       "1222   Karnataka Congress MLA Anand Singh was hospita...  \n",
       "89903  The Supreme Court has decided to intervene in ...  \n",
       "83315  Seven US companies including Oracle and Getty ...  \n",
       "60607  A 21-year-old student was allegedly molested b...  \n",
       "34997  TDP MLA Chinthamaneni Prabhakar allegedly slap...  \n",
       "49562  Actress Anushka Sharma shared a series of pict...  \n",
       "63127  Indian opener Rohit Sharma slammed four sixes ...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import  time\n",
    "\n",
    "# 뉴스 기사 데이터 불러오기\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "# 전체 샘플수가 98401개이다.\n",
    "print('전체 샘플수 :', (len(data)))\n",
    "\n",
    "# 간단히 10만 개의 샘플만 사용해보자\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-pillow",
   "metadata": {},
   "source": [
    "- 이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있다.\n",
    "- text를 요약한 것이 headlines이다.\n",
    "- 추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있다.\n",
    "- 추출적 요약을 하는 경우에는 오직 text열만을 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-wheat",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-development",
   "metadata": {},
   "source": [
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. \n",
    "만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요.\n",
    "\n",
    "이제 데이터를 불러왔으니 전처리를 진행해 볼게요.\n",
    "빈칸으로 존재하는 null 데이터, 의미는 같지만 다른 식으로 작성된 글 같은 중복 항목과 같은 \n",
    "학습할 때 방해가 되는 데이터를 먼저 솎아낼 거예요.\n",
    "\n",
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "- 데이터의 중복 샘플 유무를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "straight-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-offer",
   "metadata": {},
   "source": [
    "- 전체 샘플수가 98401였던것과 비교해보면 중복된 data가 text의 경우 41개의 샘플, headlines의 경우 121개의 샘플이 줄었다는 것을 확인할 수 있다\n",
    "- text 자체가 중복된 경우, 데이터프레임의 drop_duplicates()를 사용해서 중복 샘플을 제거하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-crisis",
   "metadata": {},
   "source": [
    "- drop_duplicates()가 중복된 Null들을 지워주기는 하겠지만, 여전히 Null 값 한 개가 어딘가 남아있을 수 있다.\n",
    "- .isnull().sum()을 사용해서 데이터프레임에 Null 값이 있는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comfortable-makeup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-tract",
   "metadata": {},
   "source": [
    "- 확인해보니 null 값이 남아있지 않았다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-combine",
   "metadata": {},
   "source": [
    "### 텍스트 정규화와 불용어 제거\n",
    "- 남은  단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있다.\n",
    "-  이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이다.\n",
    "- 이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization) 라고 한다.\n",
    "- 여기서는 텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성한다.\n",
    "##### 불용어란?\n",
    "- 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "induced-wages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n",
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cognitive-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # NLTK를 이용해 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    # Abstractive한 문장 요약 결과문이 자연스러우려면 \n",
    "    # 상대적으로 문장 길이가 짧은 summary 전처리를 할 때 불용어를 제거하지 않는게 좋다\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-football",
   "metadata": {},
   "source": [
    "- LTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개, 179개의 불용어 제거\n",
    "- 모든 영어 문자는 소문자로 만들고, 섞여있는 html 태그를 제거\n",
    "- 정규 표현식을 통해 각종 특수문자를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "future-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n",
      "time : 4.7206878662109375e-05\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(clean_text[:5])\n",
    "\n",
    "# 시간 측정\n",
    "start = time.time()  # 시작 시간 저장\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-paraguay",
   "metadata": {},
   "source": [
    "- 훈련 데이터 전체에 대해서 전처리를 수행해보자\n",
    "- 이때, text는 불용어를 제거, headlines의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "waiting-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n",
      "time : 4.7206878662109375e-05\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(clean_summary[:5])\n",
    "\n",
    "# 시간 측정\n",
    "start = time.time()  # 시작 시간 저장\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-patrol",
   "metadata": {},
   "source": [
    "### 멀티프로세싱 사용\n",
    "- 싱글 프로세스로 실행하면 데이터 전처리 하는데 많은 시간이 걸리는 것을 확인했다.\n",
    "- 이를  해결하기 위해 멀티프로세싱을 활용하여 별도의 프로세스를 생성하여 병렬처리하면 CPU수에 비례하여 획기적으로 소요 시간을 줄일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "underlying-convergence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.7837188243866  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "5.875565767288208  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['text'])  # 클라우드 기준으로 3~4분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_summary = preprocess_data(data['headlines'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "# Summary에 대해서 전처리 함수를 호출해 줄 때, \n",
    "# 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 Falses넣습니다\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-apple",
   "metadata": {},
   "source": [
    "- 시간을 보면 멀티프로세싱을 거치자 대략 700초에서 180초로 시간이 단축되었음을 확인할 수 있다.\n",
    "- 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해봐야 한다.\n",
    "- 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있기 때문이다.\n",
    "- 그렇게 되면 샘플 자체가 빈 값을 가지게 된다.\n",
    "- 쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장한 후 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "macro-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "# .isnull().sum()을 사용해서 Null 값이 생겼는지 확인해본다\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-perception",
   "metadata": {},
   "source": [
    "### 훈련데이터와 테스트데이터 나누기\n",
    "-  진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고, 문장의 시작과 끝을 표시해 줘야 한다. \n",
    "#### 샘플의 최대 길이 정하기\n",
    "- Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 본다. 시각화된 정보를 바탕으로 훈련에 사용할 샘플의 최대 길이를 정하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "british-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-supplier",
   "metadata": {},
   "source": [
    "- 요약된 정보인 headline의 경우, 최소 길이 : 1, 최대 길이 : 16, 평균 길이 : 9.299532330215534\n",
    "- text 정보인 text의 경우, 최소 길이 : 1, 최대 길이 : 60, 평균 길이 : 35.09968483123221\n",
    "- 요약된 정보의 길이가 평균적으로도 text 정보의 0.26배라는 것을 확인할 수 있었고, 최대 길이 역시 대략 0.26배라는 것을 그래프와 수치로 확인하였다.\n",
    "- 최대길이를 정확하게 확인해서 곧이 곧대로 설정할 수도 있겠지만, 최대 길이와 최소 길이를 적당히 잘라주면 100퍼센트는 아니지만 충분히 높은 확률로 필요한 데이터를 사용할 수 있다. 너무 동떨어진 샘플을 제외시키는 것이 더 유의미할 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "renewable-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "behind-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 60 이하인 샘플의 비율: 1.0\n",
      "전체 샘플 중 길이가 16 이하인 샘플의 비율: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 정확하게 설정해주면\n",
    "text_max_len =60\n",
    "summary_max_len = 16\n",
    "\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sorted-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 15 이하인 샘플의 비율: 0.9999694997966653\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 임의로 지정해보면\n",
    "text_max_len =50\n",
    "summary_max_len = 15\n",
    "\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-amendment",
   "metadata": {},
   "source": [
    "- text의 최대 길이를 60에서 50으로, headlines의 최소 길이를 16에서 15로 설정해줘도 정확도가 99퍼센트 이상인 것을 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "elegant-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98343\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-tradition",
   "metadata": {},
   "source": [
    "중복을 제외한 전체 샘플수가 98360였는데 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제한 결과 전체 샘플의 수가 17개 줄은 것을 확인할 수 있다.\n",
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "- 디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈춘다.\n",
    "##### seq2seq 훈련\n",
    "- 시작 토큰과 종료 토큰을 추가하는 이유: seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있다.\n",
    "- 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 이름을 부여해서 앞, 뒤로 추가한다.\n",
    "- decoder_input: 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름\n",
    "- decoder_target: 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름\n",
    "- 두 개의 문장 모두 headlines 열로부터 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "stuffed-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "scheduled-mills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27592 42813 23386 ... 46914 42071 78891]\n",
      "테스트 데이터의 수 : 19668\n",
      "훈련 데이터의 개수 : 78675\n",
      "훈련 레이블의 개수 : 78675\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터를 분리\n",
    "#  encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만든다\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "# 이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주어서 잘 섞인 샘플을 만든다\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "# 이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리\n",
    "# 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)\n",
    "\n",
    "# 이렇게 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분한다.\n",
    "#:표시의 위치에 주의\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-bolivia",
   "metadata": {},
   "source": [
    "- 훈련 데이터의 수는 78675, 테스트 데이터의 수는 19668개인 것을 확인했다.\n",
    "### 정수 인코딩\n",
    "#### 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
    "기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어야 한다.이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요하다. 이 과정을 단어 집합(vocabulary) 을 만든다고 표현한다. 훈련 데이터(encoder_input_train)에 대해서 단어 집합을 만들어본다.\n",
    "- Keras의 토크나이저: 입력된 훈련 데이터로부터 단어 집합을 만들 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "outer-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69597\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47463\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22134\n",
      "단어 집합에서 희귀 단어의 비율: 68.1969050390103\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4946572432787737\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의, 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "# 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여\n",
    "\n",
    "\n",
    "#이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, \n",
    "#빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 한다\n",
    "# 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인한다\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "#현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어 있다\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "# src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있다\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-papua",
   "metadata": {},
   "source": [
    "#### 통계 정보들을 해석해볼까요?\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 무려 68% 이상을 차지한다. \n",
    "하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.49%밖에 되지 않는다.\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 한다.\n",
    "위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한한다.\n",
    "토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있다.\n",
    "##### 단어 집합의 크기 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "apparent-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[447, 362, 3, 13, 1654, 380, 1860, 278, 11, 42, 240, 9, 156, 3220, 192, 1570, 993, 5880, 4072, 286, 468, 156, 176, 101, 84, 2211, 1338, 1084, 11, 6252], [406, 127, 985, 7559, 147, 1, 84, 32, 147, 3551, 6455, 124, 514, 147, 243, 527, 4323, 41, 994, 2405, 819, 4371, 147, 99, 1, 127, 1487, 4794, 627, 410], [68, 79, 535, 672, 273, 446, 1879, 2978, 2758, 178, 452, 910, 1675, 1, 3379, 535, 46, 5409, 4234, 4324, 663, 4, 263, 269, 235, 23, 399, 2139, 6123, 6708, 3823]]\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성.\n",
    "\n",
    "#texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행한다. \n",
    "#현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않는다.\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-portsmouth",
   "metadata": {},
   "source": [
    "더 이상 텍스트 데이터가 아니라 정수가 나오고 있다.\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행한다.\n",
    "케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산한다.\n",
    "\n",
    "- 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "vietnamese-float",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30139\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19702\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10437\n",
      "단어 집합에서 희귀 단어의 비율: 65.37045024718803\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.649343116141016\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-mirror",
   "metadata": {},
   "source": [
    "- 등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 65%를 차지하고 있다.\n",
    "- 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 4.69%밖에 되지 않는다.\n",
    "- 2,000을 단어 집합의 크기로 제한\n",
    "##### 단어 집합의 크기 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stainless-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 562, 38, 26, 4, 6, 18, 146, 148], [1, 50, 1092, 7, 288, 195], [1, 422, 423, 7, 226, 1225, 250], [1, 45, 364, 3, 48, 930, 88, 23], [1, 359, 17, 1854, 15, 646, 660]]\n",
      "target\n",
      "decoder  [[562, 38, 26, 4, 6, 18, 146, 148, 2], [50, 1092, 7, 288, 195, 2], [422, 423, 7, 226, 1225, 250, 2], [45, 364, 3, 48, 930, 88, 23, 2], [359, 17, 1854, 15, 646, 660, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-brisbane",
   "metadata": {},
   "source": [
    "- 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있다.\n",
    "- 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 요약문(Summary)의 경우에는 이 현상이 문제가 될 수 있다.\n",
    "- 해결방안: 약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않기 때문에 길이가 0이 된 샘플들의 실제 길이는 1로 나온다. 따라서 훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장한 후 이 샘플들은 모두 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "nutritional-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78663\n",
      "훈련 레이블의 개수 : 78663\n",
      "테스트 데이터의 개수 : 19665\n",
      "테스트 레이블의 개수 : 19665\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-cloud",
   "metadata": {},
   "source": [
    "- 예상과 달리 삭제할 데이터가 없었다. \n",
    "### 패딩하기\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해야 한다.\n",
    "그렇다면 어느 길이로 패딩을 해줄까? 최대 길이로 패딩을 해보자. 어떻게? 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "blank-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-tanzania",
   "metadata": {},
   "source": [
    "# 모델 설계하기\n",
    "- 임베딩 벡터의 차원: 128로 정의, hidden state의 크기: 256으로 정의.\n",
    "- hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터, LSTM의 용량의 크기나 뉴런의 개수\n",
    "- 인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였다\n",
    "- 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보낸다\n",
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "asian-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 128)      1024000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 50, 256), (N 394240      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 50, 256), (N 525312      lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 128)    256000      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 50, 256), (N 525312      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, None, 256),  394240      embedding_6[0][0]                \n",
      "                                                                 lstm_13[0][1]                    \n",
      "                                                                 lstm_13[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_14[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from attention import AttentionLayer\n",
    "\n",
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "# LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어준다\n",
    "\n",
    "# 디코더의 출력층\n",
    "# headlines의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 푼다\n",
    "# 그 방법으로 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) .\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-sailing",
   "metadata": {},
   "source": [
    "## Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-diabetes",
   "metadata": {},
   "source": [
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. \n",
    "실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.\n",
    "## 어텐션 메커니즘\n",
    "- 디코더의 출력층을 바꿔줘서 성능을 높여주도록 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "western-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 128)      1024000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 50, 256), (N 394240      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 50, 256), (N 525312      lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 128)    256000      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 50, 256), (N 525312      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, None, 256),  394240      embedding_6[0][0]                \n",
      "                                                                 lstm_13[0][1]                    \n",
      "                                                                 lstm_13[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_13[0][0]                    \n",
      "                                                                 lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_14[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 깃허브에 공개돼 있는 어텐션 함수를 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer\n",
    "\n",
    "# 디코더의 출력층을 수정해보겠다\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층 수정\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-watson",
   "metadata": {},
   "source": [
    "- 위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용\n",
    "- 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동하고 있다\n",
    "\n",
    "# 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "wicked-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 250s 776ms/step - loss: 3.4582 - val_loss: 2.8774\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 235s 764ms/step - loss: 2.7960 - val_loss: 2.6327\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 236s 767ms/step - loss: 2.5682 - val_loss: 2.4716\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 236s 766ms/step - loss: 2.3928 - val_loss: 2.3480\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 236s 767ms/step - loss: 2.2733 - val_loss: 2.2601\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 236s 765ms/step - loss: 2.1729 - val_loss: 2.1965\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 234s 759ms/step - loss: 2.0945 - val_loss: 2.1507\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 236s 767ms/step - loss: 2.0300 - val_loss: 2.1020\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 234s 761ms/step - loss: 1.9640 - val_loss: 2.0683\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 234s 759ms/step - loss: 1.9150 - val_loss: 2.0436\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 235s 762ms/step - loss: 1.8693 - val_loss: 2.0317\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 235s 762ms/step - loss: 1.8317 - val_loss: 2.0023\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 232s 755ms/step - loss: 1.7939 - val_loss: 1.9893\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 228s 741ms/step - loss: 1.7594 - val_loss: 1.9705\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 229s 744ms/step - loss: 1.7305 - val_loss: 1.9648\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 229s 745ms/step - loss: 1.6984 - val_loss: 1.9526\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 228s 741ms/step - loss: 1.6767 - val_loss: 1.9434\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 229s 743ms/step - loss: 1.6467 - val_loss: 1.9385\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 227s 738ms/step - loss: 1.6257 - val_loss: 1.9264\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 230s 746ms/step - loss: 1.6028 - val_loss: 1.9234\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 229s 744ms/step - loss: 1.5848 - val_loss: 1.9179\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 229s 743ms/step - loss: 1.5634 - val_loss: 1.9121\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 228s 740ms/step - loss: 1.5452 - val_loss: 1.9146\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 228s 741ms/step - loss: 1.5272 - val_loss: 1.9061\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 228s 739ms/step - loss: 1.5143 - val_loss: 1.9065\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 230s 746ms/step - loss: 1.4982 - val_loss: 1.9060\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 230s 746ms/step - loss: 1.4850 - val_loss: 1.9065\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 228s 741ms/step - loss: 1.4700 - val_loss: 1.9049\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 229s 743ms/step - loss: 1.4561 - val_loss: 1.9044\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 229s 744ms/step - loss: 1.4433 - val_loss: 1.9067\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 228s 742ms/step - loss: 1.4262 - val_loss: 1.9136\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "modified-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-picture",
   "metadata": {},
   "source": [
    "## Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-modern",
   "metadata": {},
   "source": [
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요.\n",
    "## 인퍼런스 모델 구현하기\n",
    "- 인퍼런스 모델 구현하는 이유?\n",
    "- seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르기 때문이다.\n",
    "- 훈련 단계 특징 : 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있다 > 인코더와 디코더를 엮은 통짜 모델 하나만 준비\n",
    "- 인퍼런스 단계 : 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 한다 > 이때는 인코더 모델과 디코더 모델을 분리해서 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "collectible-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 단계에서는 정수 인덱스 행렬로 존재하던 데이터를 실제 데이터로 복원해야하므로\n",
    "# 필요한 3개의 사전을 아래와 같이 미리 준비해 둔다\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 메커니즘을 구현해주는 출력층 설계\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "# 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들자\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-hamburg",
   "metadata": {},
   "source": [
    "# 모델 테스트하기\n",
    "- 테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 좋다\n",
    "- 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어보자\n",
    "- 함수를 만들 때 제외해야 할 것\n",
    " - Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을\n",
    " - Summary의 정수 시퀀스에서는 숫자 0\n",
    " - 시작 토큰의 인덱스\n",
    " - 종료 토큰의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "blocked-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-resolution",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "valid-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : american teenager received full us colleges applied including harvard stanford brown said major political sciences pursue possible second degree economics chosen college yet added see hard work paying paying paying \n",
      "실제 요약 : us teen gets to all he to \n",
      "예측 요약 :  year old us boy to replace\n",
      "\n",
      "\n",
      "원문 : adani group billion coal project australia board approved final investment decision chairman gautam adani called historic day indian investment australia notably adani invested billion project faced opposition australia largest coal project increase carbon pollution \n",
      "실제 요약 : gives final to aus project \n",
      "예측 요약 :  to billion in sports cricket\n",
      "\n",
      "\n",
      "원문 : indian pacer bhuvneshwar kumar playing india picked three wickets south africa returning competitive cricket following injury wednesday bhuvneshwar back injury third odi india england gave away runs nine overs match \n",
      "실제 요약 : for india on return from injury \n",
      "예측 요약 :  india to tour india in\n",
      "\n",
      "\n",
      "원문 : actor comedian kevin issued apology pregnant wife children video claims show woman sexually situation investigated fbi investigation owing multi million dollar extortion attempt regarding video kevin said someone trying seek financial gain mistakes \n",
      "실제 요약 : apologises to wife kids over video with another woman \n",
      "예측 요약 :  actor apologises for pregnant wife sex abuse\n",
      "\n",
      "\n",
      "원문 : bollywood star shah rukh khan co owner caribbean premier league franchise knight riders danced alongside end first innings match shah rukh also featured anthem video side knight riders team anthem sung team captain dwayne bravo \n",
      "실제 요약 : srk with in league \n",
      "예측 요약 :  srk buys rohit for kkr for new club\n",
      "\n",
      "\n",
      "원문 : indian origin girl vinay became first solo winner four years usa national contest subjected racial remarks cnn anchor anchor asked year old spell later commenting sure whether sanskrit probably used using \n",
      "실제 요약 : makes remarks at indian origin champ \n",
      "예측 요약 :  indian origin girl becomes st indian to win medal\n",
      "\n",
      "\n",
      "원문 : ex india captain mohammed offer free expert advice goa ranji team following son inclusion goa cricket association official said asaduddin son part team get free expert assistance someone work added \n",
      "실제 요약 : to offer free to goa team after son \n",
      "예측 요약 :  ex india captain offers free to son\n",
      "\n",
      "\n",
      "원문 : israeli pm benjamin netanyahu sunday announced international agreement african asylum country option leave country public security ministry said statement asylum israel mostly came sudan early \n",
      "실제 요약 : israel to \n",
      "예측 요약 :  israel pm announces to leave israel\n",
      "\n",
      "\n",
      "원문 : actress ankita making bollywood debut manikarnika queen jhansi confirmed dating businessman vicky jain nice guy yes love get know time right added earlier dated sushant singh rajput said okay friends ex boyfriend \n",
      "실제 요약 : am in love actress confirms dating \n",
      "예측 요약 :  was not to be on bigg boss\n",
      "\n",
      "\n",
      "원문 : indian rounder yuvraj singh expensive buy ipl auction history bought mumbai indians base price crore going unsold first round ipl auction year old released november kings xi punjab bought crore ipl auction \n",
      "실제 요약 : ipl buy at crore yuvraj bought by for crore \n",
      "예측 요약 :  yuvraj singh sold for crore in ipl auction\n",
      "\n",
      "\n",
      "원문 : thai authorities operation rescue football team kids coach stuck cave said three four day window attempt rescue rains next week could lead rise water levels flooded cave possibly rescue operation till january next year \n",
      "실제 요약 : day to save kids stuck in thai \n",
      "예측 요약 :  thai boys trapped in thai rescue rescue\n",
      "\n",
      "\n",
      "원문 : superintendent police abhishek tuesday broke talking death two jawans doordarshan naxal attack chhattisgarh tuesday said naxals targeted media personnel reporting faced villagers claimed naxals fired rounds two media persons \n",
      "실제 요약 : sp breaks down while about jawans death \n",
      "예측 요약 :  kill me in army\n",
      "\n",
      "\n",
      "원문 : delhi patiala house court allowed congress mp shashi tharoor travel switzerland meet former un secretary general mentor family tharoor sole accused death wife pushkar barred travelling abroad without prior permission also go un headquarters seek aid kerala floods \n",
      "실제 요약 : court allows tharoor to visit family in \n",
      "예측 요약 :  hc gandhi to tharoor\n",
      "\n",
      "\n",
      "원문 : first odi new zealand pakistan winds exceeding kmph forced umpires remove part hosts innings according rules two captains agree upon umpire approval play game without stumps case heavy winds \n",
      "실제 요약 : force nz and pakistan to play without \n",
      "예측 요약 :  pak odi series banned for sl odis\n",
      "\n",
      "\n",
      "원문 : indian cricketer former captain ms dhoni took football field play charity match alongside likes abhishek bachchan ranbir kapoor among others dhoni included indian team upcoming series australia set begin first wednesday \n",
      "실제 요약 : dhoni plays football match with abhishek ranbir \n",
      "예측 요약 :  dhoni to play in cricket ms dhoni\n",
      "\n",
      "\n",
      "원문 : bcci lost around crore due former board presidents anurag thakur former ipl chief lalit modi alleged instagram post modi said losses resulted champions league kochi kerala sahara pune warriors india indian premier league \n",
      "실제 요약 : bcci lost crore due to modi \n",
      "예측 요약 :  bcci cr for modi in ipl\n",
      "\n",
      "\n",
      "원문 : indian batsman rohit sharma said surprised test squad one match afghanistan keep enjoying game time regret enough time regret past added going forward theory whatever time make count said \n",
      "실제 요약 : was not at being from test squad rohit \n",
      "예측 요약 :  vs india will not be in afghanistan rohit\n",
      "\n",
      "\n",
      "원문 : argentine forward lionel messi made th appearance barcelona side win camp saturday year old became third player reach landmark current captain matches messi scored goals winning side times \n",
      "실제 요약 : messi plays his th match for bar as they win \n",
      "예측 요약 :  messi messi th barcelona win in\n",
      "\n",
      "\n",
      "원문 : external affairs minister sushma swaraj sunday said government provide help family akash indian origin owner shot dead us saturday year old us citizen reportedly hailed gujarat anand shot dead exchange customer club security guard \n",
      "실제 요약 : sushma help to kin of indian origin man shot in us \n",
      "예측 요약 :  sushma swaraj to family family for killing report\n",
      "\n",
      "\n",
      "원문 : central board direct taxes chairman sushil chandra said employees best taxpayers deserve better treatment put standard persons said added crore taxpayers paid lakh crore taxes crore business people gave crore \n",
      "실제 요약 : employees are best chairman \n",
      "예측 요약 :  of people to create jobs\n",
      "\n",
      "\n",
      "원문 : prime minister narendra modi sunday launched bharat pradhan mantri jan jharkhand ranchi scheme offers annual cover lakh economically weaker sections society world largest public health insurance scheme benefit crore people across country \n",
      "실제 요약 : pm modi launches world largest govt scheme \n",
      "예측 요약 :  pm modi launches bharat bharat for bharat\n",
      "\n",
      "\n",
      "원문 : paytm founder vijay shekhar sharma said met amazon raise money startup series round added call alibaba founder jack investment deal way amazon office said alibaba softbank \n",
      "실제 요약 : met amazon to raise money in series paytm founder \n",
      "예측 요약 :  paytm founder wanted paytm founder\n",
      "\n",
      "\n",
      "원문 : deepika padukone produce star film acid attack survivor agarwal confirming news deepika said heard story made impact personally needed go beyond decision turn producer attacked year old man \n",
      "실제 요약 : deepika to and star in film on attack \n",
      "예측 요약 :  deepika deepika star in film attack\n",
      "\n",
      "\n",
      "원문 : growing demand oneplus looking expand offline reach experience stores stores well expand partnership already looking locations delhi mumbai next experience stores exclusive stores open cities like ahmedabad chennai hyderabad kolkata pune \n",
      "실제 요약 : oneplus plans to its in india \n",
      "예측 요약 :  to launch new york city service\n",
      "\n",
      "\n",
      "원문 : delhi daredevils player rabada ran mumbai indians harbhajan singh saturday ball towards stumps rabada bowled striker hardik pandya blocked batsman remained front stumps batsmen attempted run rabada kicked ball striker end \n",
      "실제 요약 : runs out harbhajan by the ball \n",
      "예측 요약 :  dhoni gets training for ball at\n",
      "\n",
      "\n",
      "원문 : portion first odi afghanistan windies featured stumps without strong winds friday made impossible remain place rules allow cricket played without strong winds umpires responsibility taking calls wickets broken cases run \n",
      "실제 요약 : force afghanistan to play without \n",
      "예측 요약 :  afghanistan odi series system\n",
      "\n",
      "\n",
      "원문 : maharashtra government friday tata institute social sciences fee financial support scheduled tribe students comes bandh organised students union withdrawal financial aid government india post students sc st category across institute nnn \n",
      "실제 요약 : st students to get fee maharashtra govt \n",
      "예측 요약 :  maharashtra govt to pay fee hike for\n",
      "\n",
      "\n",
      "원문 : aap named national spokesperson sanjay singh social activist sushil gupta former president institute chartered india nd gupta three rajya sabha elections slamming party decision aap leader kumar said delhi chief minister arvind kejriwal words party \n",
      "실제 요약 : aap names its three for rajya sabha elections \n",
      "예측 요약 :  aap singh singh singh joins\n",
      "\n",
      "\n",
      "원문 : police monday said year old man allegedly shot dead following car collided scooter delhi man sustained bullet injury following rushed hospital doctors declared brought dead died due excessive bleeding police said \n",
      "실제 요약 : man shot dead after his car with in delhi \n",
      "예측 요약 :  man shoots himself dead in car in delhi\n",
      "\n",
      "\n",
      "원문 : advertising standards council india found advertisements companies including bharti airtel itc republic tv forbes system idea cellular among others misleading upheld complaints advertisements across personal care healthcare education food beverages \n",
      "실제 요약 : airtel tv ads found to be \n",
      "예측 요약 :  airtel to ban ads from airtel\n",
      "\n",
      "\n",
      "원문 : paytm japanese market first time wallet service service joint venture softbank yahoo japan enables users transfer money bank account wallet make payments based paytm technology also deployed india \n",
      "실제 요약 : paytm into japan with service \n",
      "예측 요약 :  paytm shares first ever service in paytm\n",
      "\n",
      "\n",
      "원문 : gujarat government decided give nine day holiday school college students celebrate festival october students able enjoy festival without worry coming school college next day mos education said last time gujarat announced similar holidays \n",
      "실제 요약 : gujarat declares day for school \n",
      "예측 요약 :  gujarat govt to provide school kids for kids\n",
      "\n",
      "\n",
      "원문 : year old woman allegedly gave birth girl public toilet mumbai also attempted woman however left inside toilet heard people entering facility police filed complaint woman investigating family role case \n",
      "실제 요약 : woman tries to her girl in public toilet in mumbai \n",
      "예측 요약 :  woman gives birth to girl in mumbai\n",
      "\n",
      "\n",
      "원문 : america largest gun manufacturer american brands reported fall revenue compared quarter last year despite president donald trump support gun owners gun sales usually rise us politicians threaten control gun rights politicians like trump support gun owners provide little boost \n",
      "실제 요약 : us gun sales fall despite trump gun rights \n",
      "예측 요약 :  us market value over trade war\n",
      "\n",
      "\n",
      "원문 : former windies captain brian lara became first cricketer history score plus runs first class innings june playing lara slammed record runs boundaries world record innings lara spent almost eight hours crease knock \n",
      "실제 요약 : slammed record in hours hit in and \n",
      "예측 요약 :  st player to score runs in an innings\n",
      "\n",
      "\n",
      "원문 : taken driver delivering amazon uk owner richard ceo jeff bezos returned said amazon employee went driver home found brought back driver would longer deliver packages amazon spokesperson said \n",
      "실제 요약 : taken by amazon delivery man owner ceo bezos \n",
      "예측 요약 :  man who driver quits ambani\n",
      "\n",
      "\n",
      "원문 : ukrainian company service run father daughter team investigated causing ransomware attack spread countries virus primarily spread via update issued accounting software developed service two could face criminal charges found guilty taking action despite knowing infection \n",
      "실제 요약 : father daughter being for attack \n",
      "예측 요약 :  father daughter arrested for attack on\n",
      "\n",
      "\n",
      "원문 : people board us military cargo plane feared killed crashed state georgia wednesday officials said plane crashed training flight near head international airport professional firefighters association identified aircraft military \n",
      "실제 요약 : killed as military plane crashes in us \n",
      "예측 요약 :  us military plane crashes in\n",
      "\n",
      "\n",
      "원문 : french environment minister announced resignation live radio interview tuesday citing government lack efforts addressing environmental issues fighting climate change said informed president emmanuel macron pm decision making announcement added decision life \n",
      "실제 요약 : french minister resigns during live \n",
      "예측 요약 :  french minister quits after criticism\n",
      "\n",
      "\n",
      "원문 : england become first ever team feature test matches achieving feat taking field india wednesday england played first test lost drawn tests played england followed australia played test matches \n",
      "실제 요약 : england first team in cricket history to play tests \n",
      "예측 요약 :  st ever int cricketer to play test wickets in india\n",
      "\n",
      "\n",
      "원문 : kiran rao made directorial debut make comeback director years working eight story ideas none satisfied last seven years added finally one finishing script film said \n",
      "실제 요약 : rao to make as director after years \n",
      "예측 요약 :  to be made years ago\n",
      "\n",
      "\n",
      "원문 : former indian captain mahendra singh dhoni seen bowling spin indore ahead third india odi official facebook page indian cricket team shared video dhoni bowling spin captioned nobody quick ms dhoni behind stumps watch try spin bowling \n",
      "실제 요약 : dhoni in ahead of third india australia odi \n",
      "예측 요약 :  dhoni posts video of dhoni in ms dhoni odi\n",
      "\n",
      "\n",
      "원문 : bengaluru police commissioner kumar monday ordered probe harassment year old rape victim personnel nagar police station victim alleged policeman demanded fuel money order travel arrest accused police station staff also allegedly questioned victim \n",
      "실제 요약 : probe ordered into luru rape victim harassment by police \n",
      "예측 요약 :  bengaluru police file probe against rape victim\n",
      "\n",
      "\n",
      "원문 : india fiscal deficit april november period stood lakh crore target current financial year gap government revenue expenditure stood november last year finance minister arun jaitley assured government track meet fiscal deficit target gdp \n",
      "실제 요약 : april of fy target \n",
      "예측 요약 :  india revenue jumps to crore in fy\n",
      "\n",
      "\n",
      "원문 : talking looks forward wedding sonam kapoor said would rather wedding home anywhere else think much money spent would rather give away added earlier reported sonam get married may businessman anand ahuja may mumbai \n",
      "실제 요약 : have wedding at home than sonam \n",
      "예측 요약 :  sonam and will not want to get married says sonam\n",
      "\n",
      "\n",
      "원문 : amazon founder world third richest person jeff bezos sold billion company stock part planned comes month bezos said would spend amount annually space exploration startup blue origin still owns crore amazon shares commerce company \n",
      "실제 요약 : bezos sells bn amazon stock to fund his startup \n",
      "예측 요약 :  amazon founder bezos net worth drops billion in days\n",
      "\n",
      "\n",
      "원문 : us returned year old copy letter written christopher vatican written letter spanish asking funds another discovered new world eight page letter kept vatican library stolen replaced fake one \n",
      "실제 요약 : us returns yr old letter to \n",
      "예측 요약 :  year old us teen asks for not\n",
      "\n",
      "\n",
      "원문 : india lost belgium penalties final second leg four nations tournament new zealand sunday india held world number three side draw end regulation time losing penalty shootout india lost belgium first leg final well \n",
      "실제 요약 : india lose penalty to in four nations final \n",
      "예측 요약 :  india lose to reach final of asian\n",
      "\n",
      "\n",
      "원문 : lakh companies permanent account number file income tax returns assessment year delhi number companies lakh notices issued companies carrying business period two immediately failed file financial statements \n",
      "실제 요약 : over lakh firms have but did not file tax returns \n",
      "예측 요약 :  lakh of lakh in returns to tax returns\n",
      "\n",
      "\n",
      "원문 : woman named anna featured promotional video akshay kumar clarified transgender trolled video content video shown coming men bathroom akshay log bhi anna claimed people calling man \n",
      "실제 요약 : am not transgender woman in akshay video for \n",
      "예측 요약 :  woman who is the features of the robot\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-investor",
   "metadata": {},
   "source": [
    "긍정적인 측면에서는, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보인다\n",
    "일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 한다는 점이 신기하다.\n",
    "\n",
    "아쉬운 측면에서는, 좋지 않은 요약의 예도 꽤 있다는 점이다.\n",
    "성능을 어떻게 개선해볼지 다양한 방법을 알아보는 것도 의미가 있을것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-verification",
   "metadata": {},
   "source": [
    "## Step 5. Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-liver",
   "metadata": {},
   "source": [
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높다.\n",
    "다시 말해서 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮다.\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보자\n",
    "### 데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "female-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "# 매트릭스 시놉시스를 다운로드\n",
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "\n",
    "# text에는 매트릭스 시놉시스가 문자열로 저장되어 있다. \n",
    "# 출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인\n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-defendant",
   "metadata": {},
   "source": [
    "### summarize 사용하기\n",
    "Summa의 summarize()의 인자로 사용되는 값들\n",
    "- text (str) : 요약할 테스트.\n",
    "- ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값\n",
    "- words (int or None, optional) – 출력에 포함할 단어 수.\n",
    " - 만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.\n",
    "- split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환\n",
    "\n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행하기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있다. 비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여본다. 원문의 0.005%만을 출력하도록 설정했어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "lovely-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n",
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n",
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))\n",
    "\n",
    "# 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 하면 된다\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))\n",
    "\n",
    "# 단어의 수로 요약문의 크기를 조절, 일단 단어를 50개만 선택\n",
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-sensitivity",
   "metadata": {},
   "source": [
    "회고: 확실히 자원을 적게 투입해서 그런지 성능이 생각보다 좋지 않았다. Naver의 요약봇은 그래도 요약한 말이 말이 되고 괜찮았는데 역시 컴퓨팅 파워가 많은 기업에서 좋은 성능을 구현할 수 있는 것 같다. 내가 중고등학교를 다닐 때만 해도 구글 번역기를 돌리면 말이 안되고 문맥이 자연스럽게 이어지지 않았는데 요즘 구글 번역기를 보면 꽤 자연스럽게 번역이 되는 것 같다. 외국 여행을 해도 번역기가 있으면 따로 통역사나 가이드 없이도 여행을 할 수 있는 환경이 마련된 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-frame",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
