{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "injured-kansas",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certain-choice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-words",
   "metadata": {},
   "source": [
    "## 2) 데이터로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "average-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mineral-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 함수들 정리\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-canberra",
   "metadata": {},
   "source": [
    "## 3) 모델구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "underlying-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(X_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(X_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "christian-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(X_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "biblical-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grave-sector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "certain-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(X_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "charged-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "diverse-globe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "         14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458, 4468,\n",
       "         66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,  838,\n",
       "        112,   50,  670,    2,    9,   35,  480,  284,    5,  150,    4,\n",
       "        172,  112,  167,    2,  336,  385,   39,    4,  172, 4536, 1111,\n",
       "         17,  546,   38,   13,  447,    4,  192,   50,   16,    6,  147,\n",
       "       2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,   71,\n",
       "         87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,    4,\n",
       "         22,   17,  515,   17,   12,   16,  626,   18,    2,    5,   62,\n",
       "        386,   12,    8,  316,    8,  106,    5,    4, 2223, 5244,   16,\n",
       "        480,   66, 3785,   33,    4,  130,   12,   16,   38,  619,    5,\n",
       "         25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,   22,\n",
       "         12,  215,   28,   77,   52,    5,   14,  407,   16,   82,    2,\n",
       "          8,    4,  107,  117, 5952,   15,  256,    4,    2,    7, 3766,\n",
       "          5,  723,   36,   71,   43,  530,  476,   26,  400,  317,   46,\n",
       "          7,    4,    2, 1029,   13,  104,   88,    4,  381,   15,  297,\n",
       "         98,   32, 2071,   56,   26,  141,    6,  194, 7486,   18,    4,\n",
       "        226,   22,   21,  134,  476,   26,  480,    5,  144,   30, 5535,\n",
       "         18,   51,   36,   28,  224,   92,   25,  104,    4,  226,   65,\n",
       "         16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,  113,\n",
       "        103,   32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-property",
   "metadata": {},
   "source": [
    "## 4) 모델구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-authority",
   "metadata": {},
   "source": [
    "### 4-1) LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foreign-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "structured-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = X_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-johns",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-painting",
   "metadata": {},
   "source": [
    "- 모델 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minimal-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30/30 [==============================] - 7s 140ms/step - loss: 0.6927 - accuracy: 0.5061 - val_loss: 0.6886 - val_accuracy: 0.5746\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.6816 - accuracy: 0.5791 - val_loss: 0.6241 - val_accuracy: 0.6607\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 3s 113ms/step - loss: 0.5894 - accuracy: 0.7674 - val_loss: 0.5504 - val_accuracy: 0.7559\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.5101 - accuracy: 0.8355 - val_loss: 0.4937 - val_accuracy: 0.8485\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.4455 - accuracy: 0.8940 - val_loss: 0.4582 - val_accuracy: 0.8559\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.3891 - accuracy: 0.9212 - val_loss: 0.4470 - val_accuracy: 0.8574\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.3364 - accuracy: 0.9411 - val_loss: 0.4225 - val_accuracy: 0.8614\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.3062 - accuracy: 0.9496 - val_loss: 0.4301 - val_accuracy: 0.8589\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.2744 - accuracy: 0.9550 - val_loss: 0.4150 - val_accuracy: 0.8591\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.2421 - accuracy: 0.9619 - val_loss: 0.4219 - val_accuracy: 0.8591\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2199 - accuracy: 0.9642 - val_loss: 0.4020 - val_accuracy: 0.8495\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1948 - accuracy: 0.9692 - val_loss: 0.4409 - val_accuracy: 0.8571\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.1806 - accuracy: 0.9678 - val_loss: 0.4556 - val_accuracy: 0.8529\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1655 - accuracy: 0.9674 - val_loss: 0.4149 - val_accuracy: 0.8489\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1495 - accuracy: 0.9708 - val_loss: 0.4624 - val_accuracy: 0.8516\n"
     ]
    }
   ],
   "source": [
    "#partial_X_train = partial_X_train.astype('float64')\n",
    "#partial_y_train = partial_y_train.astype('float64')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=15  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-inquiry",
   "metadata": {},
   "source": [
    "- 모델 학습 평가해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "interim-bolivia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 115ms/step - loss: 0.1323 - accuracy: 0.9729 - val_loss: 0.4819 - val_accuracy: 0.8518\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1220 - accuracy: 0.9750 - val_loss: 0.4426 - val_accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1092 - accuracy: 0.9763 - val_loss: 0.4564 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0946 - accuracy: 0.9813 - val_loss: 0.4860 - val_accuracy: 0.8468\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0920 - accuracy: 0.9795 - val_loss: 0.4961 - val_accuracy: 0.8451\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0839 - accuracy: 0.9817 - val_loss: 0.5512 - val_accuracy: 0.8476\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0816 - accuracy: 0.9817 - val_loss: 0.5178 - val_accuracy: 0.8394\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0755 - accuracy: 0.9823 - val_loss: 0.5619 - val_accuracy: 0.8444\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0674 - accuracy: 0.9852 - val_loss: 0.5642 - val_accuracy: 0.8437\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0683 - accuracy: 0.9846 - val_loss: 0.5679 - val_accuracy: 0.8442\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0594 - accuracy: 0.9879 - val_loss: 0.6042 - val_accuracy: 0.8470\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0677 - accuracy: 0.9847 - val_loss: 0.5576 - val_accuracy: 0.8379\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0649 - accuracy: 0.9843 - val_loss: 0.5692 - val_accuracy: 0.8411\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0529 - accuracy: 0.9887 - val_loss: 0.5844 - val_accuracy: 0.8398\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0516 - accuracy: 0.9888 - val_loss: 0.6428 - val_accuracy: 0.8432\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0474 - accuracy: 0.9897 - val_loss: 0.5984 - val_accuracy: 0.8164\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1092 - accuracy: 0.9653 - val_loss: 0.6184 - val_accuracy: 0.8370\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0624 - accuracy: 0.9854 - val_loss: 0.6199 - val_accuracy: 0.8384\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0526 - accuracy: 0.9885 - val_loss: 0.6071 - val_accuracy: 0.8383\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0484 - accuracy: 0.9893 - val_loss: 0.6592 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-harmony",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "retained-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "activated-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzHElEQVR4nO3deZgU1b3/8fcHFAFBZXFBUMBERQ2yjRgxbtEkaIy7USRR1CsuUaO/mxiMG5dIEhOTePUaDcZdDBpzQ0zcErfodR8EUVQUDSqIBkEBRZTl+/vj1EDT9Mx0M9PTM/B5PU89XXVqO1XTU98+51SdUkRgZmZWrFaVzoCZmbUsDhxmZlYSBw4zMyuJA4eZmZXEgcPMzEriwGFmZiVx4LAGk3SfpBMae9lKkjRT0gFl2G5I+mI2fq2ki4pZdi32M1zS39c2n2Z1kZ/jWD9J+jhnsj3wGbA8mz41IsY3fa6aD0kzgf+IiAcbebsBbB8RMxprWUm9gH8BG0bEskbJqFkdNqh0BqwyIqJDzXhdF0lJG/hiZM2Fv4/Ng6uqbDWS9pU0S9KPJL0H3Cipk6S/SZor6cNsvEfOOo9K+o9sfISk/5N0ebbsvyQduJbL9pb0mKRFkh6UdLWk22rJdzF5/ImkJ7Lt/V1S15z535X0lqR5ki6o4/zsLuk9Sa1z0g6XNDUbHyzpKUkfSZoj6X8ktallWzdJujRn+ofZOu9KOilv2W9KmixpoaR3JI3Omf1Y9vmRpI8l7VFzbnPWHyLpOUkLss8hxZ6bEs9zZ0k3ZsfwoaSJOfMOlTQlO4Y3JA3N0lerFpQ0uubvLKlXVmV3sqS3gYez9D9mf4cF2Xdkl5z120n6Vfb3XJB9x9pJukfSWXnHM1XS4YWO1WrnwGGFbAV0BnoCI0nfkxuz6W2BT4H/qWP93YHpQFfgF8D1krQWy94OPAt0AUYD361jn8Xk8TjgRGALoA3wAwBJOwPXZNvfOttfDwqIiGeAT4Cv5m339mx8OXBudjx7APsDZ9SRb7I8DM3y8zVgeyC/feUT4HhgM+CbwOmSDsvm7Z19bhYRHSLiqbxtdwbuAa7Mju3XwD2SuuQdwxrnpoD6zvOtpKrPXbJt/SbLw2DgFuCH2THsDcysZR+F7APsBHwjm76PdJ62AJ4HcqtWLwcGAUNI3+PzgBXAzcB3ahaS1A/oTjo3VoqI8LCeD6R/4AOy8X2Bz4G2dSzfH/gwZ/pRUlUXwAhgRs689kAAW5WyLOmitAxonzP/NuC2Io+pUB4vzJk+A7g/G78YmJAzb+PsHBxQy7YvBW7IxjuSLuo9a1n2HODPOdMBfDEbvwm4NBu/Afh5znI75C5bYLtXAL/Jxntly26QM38E8H/Z+HeBZ/PWfwoYUd+5KeU8A91IF+hOBZb7XU1+6/r+ZdOja/7OOce2XR152CxbZlNSYPsU6FdgubbAh6R2I0gB5rfl+J9a1weXOKyQuRGxpGZCUntJv8uK/gtJVSOb5VbX5HmvZiQiFmejHUpcdmtgfk4awDu1ZbjIPL6XM744J09b5247Ij4B5tW2L1Lp4ghJGwFHAM9HxFtZPnbIqm/ey/LxU1Lpoz6r5QF4K+/4dpf0SFZFtAA4rcjt1mz7rby0t0i/tmvUdm5WU8953ob0N/uwwKrbAG8Umd9CVp4bSa0l/Tyr7lrIqpJL12xoW2hf2Xf6DuA7kloBw0glJCuRA4cVkn+r3X8COwK7R8QmrKoaqa36qTHMATpLap+Ttk0dyzckj3Nyt53ts0ttC0fEy6QL74GsXk0FqcrrVdKv2k2AH69NHkglrly3A3cD20TEpsC1Odut79bId0lVS7m2BWYXka98dZ3nd0h/s80KrPcO8IVatvkJqbRZY6sCy+Qe43HAoaTqvE1JpZKaPHwALKljXzcDw0lViIsjr1rPiuPAYcXoSCr+f5TVl19S7h1mv+CrgdGS2kjaA/hWmfJ4F3CwpK9kDdljqP9/43bg+6QL5x/z8rEQ+FhSH+D0IvNwJzBC0s5Z4MrPf0fSr/klWXvBcTnz5pKqiLarZdv3AjtIOk7SBpKOAXYG/lZk3vLzUfA8R8QcUtvDb7NG9A0l1QSW64ETJe0vqZWk7tn5AZgCHJstXwUcVUQePiOVCtuTSnU1eVhBqvb7taSts9LJHlnpkCxQrAB+hUsba82Bw4pxBdCO9GvuaeD+JtrvcFID8zxSu8IdpAtGIVewlnmMiGnA90jBYA6pHnxWPav9gdRg+3BEfJCT/gPSRX0RcF2W52LycF92DA8DM7LPXGcAYyQtIrXJ3Jmz7mJgLPCE0t1cX87b9jzgYFJpYR6psfjgvHwX6wrqPs/fBZaSSl3/JrXxEBHPkhrffwMsAP7JqlLQRaQSwofAf7F6Ca6QW0glvtnAy1k+cv0AeBF4DpgPXMbq17pbgL6kNjNbC34A0FoMSXcAr0ZE2Us8tu6SdDwwMiK+Uum8tFQucVizJWk3SV/IqjaGkuq1J1Y4W9aCZdWAZwDjKp2XlsyBw5qzrUi3in5Megbh9IiYXNEcWYsl6Ruk9qD3qb86zOrgqiozMyuJSxxmZlaS9aKTw65du0avXr0qnQ0zsxZl0qRJH0TE5vnp60Xg6NWrF9XV1ZXOhplZiyIpv8cBwFVVZmZWIgcOMzMriQOHmZmVxIHDzMxK4sBhZmYlceAws2Zn/Hjo1QtatUqf48fXt4blKvf5Wy9uxzWzlmP8eBg5EhZnr/B66600DTB8eOXy1VI0xflzicPMmpULLlh10auxeHFKL1ZLL7E0JP+Ncf7q48BhZo2uIRe+t98uLb3QvkeOTL+0I1b94m4pwaOh+W/o+SuGA4dZM9SSfzE39MK3bf5Lc+tJz9cUv7jrU8kSQ0PPX1EiYp0fBg0aFGaluO22iJ49I6T0edttTbf+bbdFtG8fkS67aWjfvvQ8VErPnqvnvWbo2bO49Rt6/FLh/Utre0SlqXT+G/P7A1RHgWtqxS/qTTE4cFgpGvqP19D1G3rhbQwNCXyNceFuyP4rff4auv/GyH9Df/jUcOCwJtVYX9xK7L/S//gt/RdzpS/clS6xNacSQ0M5cFiTqfQXv9JVBQ1dv9K/OCtd1dQYKvnDpdJ/v8bkwGFNptK/OCtdYqj0hbfSgbMmD83hwlcJzSFwNhYHDitJS67jrnRVQWNcOFpyVZutO4HTgWM9U8m7eir9i7s5VBVU8sJR6cBp6w4HjvVIpS+8LX3/LV1zCJy2bnDgWI80h7t6WnJVV0u3vgdOazy1BQ6leeu2qqqqWJ/eOd6qVbpc5JNgxYr61+/VKz3tm69nT5g5s6G5a/77XxeMH5+eNH777fTE8Nix7iDQSidpUkRU5ae7y5F1UEO7HBg7Ftq3Xz2tffuU3hQqvf91wfDhKciuWJE+HTSsMZU1cEgaKmm6pBmSRhWY31PSQ5KmSnpUUo8sfT9JU3KGJZIOy+bdJOlfOfP6l/MYKqUhfd009MI7fDiMG5d+4Uvpc9y4prv4VHr/ZlaPQvVXjTEArYE3gO2ANsALwM55y/wROCEb/ypwa4HtdAbmA+2z6ZuAo0rJS0tr46j07ZxmZhG1t3GUs8QxGJgREW9GxOfABODQvGV2Bh7Oxh8pMB/gKOC+iFhcYN46qTF693RVhZmVSzkDR3fgnZzpWVlarheAI7Lxw4GOkrrkLXMs8Ie8tLFZ9dZvJG3UWBnOVclurZuiP30zq11L7ta+KVS6cfwHwD6SJgP7ALOB5TUzJXUD+gIP5KxzPtAH2I1UjfWjQhuWNFJStaTquXPnlpSpxngRTEO+eE3Sn76ZFdTSXwTVJArVXzXGAOwBPJAzfT5wfh3LdwBm5aV9HxhXxzr7An+rLy+ltnFU+gE034dvVjnucmUVKtDG8RywvaTektqQqpzuzl1AUldJNXk4H7ghbxvDyKumykohSBJwGPBSY2e8oVVFDW2j8F1FZpXjquL6lS1wRMQy4ExSNdMrwJ0RMU3SGEmHZIvtC0yX9BqwJbDyhlFJvYBtgH/mbXq8pBeBF4GuwKWNnfeGVhU1xhfPjdtmleGq4vptUM6NR8S9wL15aRfnjN8F3FXLujNZszGdiPhq4+ZyTWPHpjrN3FJDKc9BbLtt4Sef/cUza/4a+v+/Pqh043iz1NCqIj/5bNZyuaq4fu6rqkzcV5CZtXS19VVV1qqq9dnw4Q4UZrZuclWVmZmVxIHDzMxK4sBhZmYlceAwM7OSOHCYmVlJHDjMzKwkDhxmZlYSBw4zMyuJA4eZmZXEgcPMzEriwGFmZiVx4DAzs5I4cJiZWUkcOMzMrCQOHGZmVhIHDjMzK4kDh5mZlaSsgUPSUEnTJc2QNKrA/J6SHpI0VdKjknrkzFsuaUo23J2T3lvSM9k275DUppzHYGZmqytb4JDUGrgaOBDYGRgmaee8xS4HbomIXYExwM9y5n0aEf2z4ZCc9MuA30TEF4EPgZPLdQxmZramcpY4BgMzIuLNiPgcmAAcmrfMzsDD2fgjBeavRpKArwJ3ZUk3A4c1VobNzKx+5Qwc3YF3cqZnZWm5XgCOyMYPBzpK6pJNt5VULelpSYdlaV2AjyJiWR3bBEDSyGz96rlz5zbwUMzMrEalG8d/AOwjaTKwDzAbWJ7N6xkRVcBxwBWSvlDKhiNiXERURUTV5ptv3qiZNjNbn21Qxm3PBrbJme6Rpa0UEe+SlTgkdQCOjIiPsnmzs883JT0KDAD+BGwmaYOs1LHGNs3MrLzKWeJ4Dtg+uwuqDXAscHfuApK6SqrJw/nADVl6J0kb1SwD7Am8HBFBags5KlvnBOAvZTwGMzPLU7bAkZUIzgQeAF4B7oyIaZLGSKq5S2pfYLqk14AtgbFZ+k5AtaQXSIHi5xHxcjbvR8D/kzSD1OZxfbmOwczM1qT0I37dVlVVFdXV1ZXOhplZiyJpUtbWvJpKN46bmVkL48BhZmYlceAwM7OSOHCYmVlJHDjMzKwkDhxmZlYSBw4zMyuJA4eZmZXEgcPMzEriwGFmZiVx4DAzs5I4cJiZWUkcOMzMrCQOHGZmVhIHDjMzK4kDh5mZlcSBw8zMSuLAYWZmJXHgMDOzkjhwmJlZScoaOCQNlTRd0gxJowrM7ynpIUlTJT0qqUeW3l/SU5KmZfOOyVnnJkn/kjQlG/qX8xjMzGx1ZQsckloDVwMHAjsDwyTtnLfY5cAtEbErMAb4WZa+GDg+InYBhgJXSNosZ70fRkT/bJhSrmMwM7M1lbPEMRiYERFvRsTnwATg0LxldgYezsYfqZkfEa9FxOvZ+LvAv4HNy5hXMzMrUjkDR3fgnZzpWVlarheAI7Lxw4GOkrrkLiBpMNAGeCMneWxWhfUbSRsV2rmkkZKqJVXPnTu3IcdhZmY5Kt04/gNgH0mTgX2A2cDympmSugG3AidGxIos+XygD7Ab0Bn4UaENR8S4iKiKiKrNN3dhxcyssWxQxm3PBrbJme6Rpa2UVUMdASCpA3BkRHyUTW8C3ANcEBFP56wzJxv9TNKNpOBjZmZNpJwljueA7SX1ltQGOBa4O3cBSV0l1eThfOCGLL0N8GdSw/ldeet0yz4FHAa8VMZjMDOzPGULHBGxDDgTeAB4BbgzIqZJGiPpkGyxfYHpkl4DtgTGZunfBvYGRhS47Xa8pBeBF4GuwKXlOgYzM1uTIqLuBaRvAffktDG0OFVVVVFdXV3pbJiZtSiSJkVEVX56MSWOY4DXJf1CUp/Gz5qZmbUk9QaOiPgOMIB0O+xN2RPdIyV1LHvuzMys2SmqjSMiFgJ3kR7i60Z65uJ5SWeVMW9mZtYM1Xs7btaQfSLwReAWYHBE/FtSe+Bl4KryZtHMWrKlS5cya9YslixZUumsWC3atm1Ljx492HDDDYtavpjnOI4EfhMRj+UmRsRiSSevRR7NbD0ya9YsOnbsSK9evUh30VtzEhHMmzePWbNm0bt376LWKaaqajTwbM2EpHaSemU7fGgt8mlm65ElS5bQpUsXB41mShJdunQpqURYTOD4I5B7K+7yLM3MrCgOGs1bqX+fYgLHBlnvtgBk421KzJeZWUXMmzeP/v37079/f7baaiu6d+++cvrzzz+vc93q6mrOPvvsevcxZMiQxspui1BM4Jib86Q3kg4FPihflsxsfTZ+PPTqBa1apc/x4xu2vS5dujBlyhSmTJnCaaedxrnnnrtyuk2bNixbtqzWdauqqrjyyivr3ceTTz7ZsEy2MMUEjtOAH0t6W9I7pN5oTy1vtsxsfTR+PIwcCW+9BRHpc+TIhgePfCNGjOC0005j991357zzzuPZZ59ljz32YMCAAQwZMoTp06cD8Oijj3LwwQcDMHr0aE466ST23Xdftttuu9UCSocOHVYuv++++3LUUUfRp08fhg8fTk3vHPfeey99+vRh0KBBnH322Su3m2vmzJnstddeDBw4kIEDB64WkC677DL69u1Lv379GDUqvVB1xowZHHDAAfTr14+BAwfyxhtvrLHNcqj3rqqIeAP4ctZ7LRHxcdlzZWbrpQsugMWLV09bvDilDx/euPuaNWsWTz75JK1bt2bhwoU8/vjjbLDBBjz44IP8+Mc/5k9/+tMa67z66qs88sgjLFq0iB133JHTTz99jVtYJ0+ezLRp09h6663Zc889eeKJJ6iqquLUU0/lscceo3fv3gwbNqxgnrbYYgv+8Y9/0LZtW15//XWGDRtGdXU19913H3/5y1945plnaN++PfPnzwdg+PDhjBo1isMPP5wlS5awYkXT9AxVVLfqkr4J7AK0rWlEiYgxZcyXma2H3n67tPSGOProo2ndujUACxYs4IQTTuD1119HEkuXLi24zje/+U022mgjNtpoI7bYYgvef/99evTosdoygwcPXpnWv39/Zs6cSYcOHdhuu+1W3u46bNgwxo0bt8b2ly5dyplnnsmUKVNo3bo1r732GgAPPvggJ554Iu3btwegc+fOLFq0iNmzZ3P44YcD6VmMplJvVZWka0n9VZ0FCDga6FnmfJnZemjbbUtLb4iNN9545fhFF13Efvvtx0svvcRf//rXWm9N3WijVS8cbd26dcH2kWKWqc1vfvMbttxyS1544QWqq6vrbbyvlGLaOIZExPHAhxHxX8AewA7lzZaZrY/GjoXsR/VK7dun9HJasGAB3bunN1vfdNNNjb79HXfckTfffJOZM2cCcMcdd9Saj27dutGqVStuvfVWli9PL0T92te+xo033sjirB5v/vz5dOzYkR49ejBx4kQAPvvss5Xzy62YwFETehdL2hpYSuqvysysUQ0fDuPGQc+eIKXPceMav30j33nnncf555/PgAEDSiohFKtdu3b89re/ZejQoQwaNIiOHTuy6aabrrHcGWecwc0330y/fv149dVXV5aKhg4dyiGHHEJVVRX9+/fn8ssvB+DWW2/lyiuvZNddd2XIkCG89957jZ73Qop5H8dFpP6o9geuBgK4LiIuLn/2Goffx2FWOa+88go77bRTpbNRcR9//DEdOnQgIvje977H9ttvz7nnnlvpbK1U6O+0Vu/jyF7r+lBEfBQRfyK1bfRpSUHDzKw5uO666+jfvz+77LILCxYs4NRTW+5TDXXeVRURKyRdTXofBxHxGfBZU2TMzGxdcu655zarEkZDFNPG8ZCkI+XOZszMjOICx6mkTg0/k7RQ0iJJC4vZuKShkqZLmiFpVIH5PSU9JGmqpEcl9ciZd4Kk17PhhJz0QZJezLZ5pQOamVnTKubVsR0jolVEtImITbLpTepbT1JrUmP6gcDOwDBJO+ctdjlwS0TsCowBfpat2xm4BNgdGAxcIqlTts41wCnA9tkwtIjjNDOzRlLMGwD3LpSe/2KnAgYDMyLizWw7E4BDSW8NrLEz8P+y8UeAidn4N4B/RMT8bN1/AEMlPQpsEhFPZ+m3AIcB99V3HGZm1jiKqar6Yc5wEfBX0sud6tMdeCdnelaWlusF4Ihs/HCgo6QudazbPRuva5sASBopqVpS9dy5c4vIrpmti/bbbz8eeOCB1dKuuOIKTj/99FrX2Xfffam5hf+ggw7io48+WmOZ0aNHr3yeojYTJ07k5ZdX/Va++OKLefDBB0vIffNUTFXVt3KGrwFfAj5spP3/ANhH0mRgH2A26UVRDRYR4yKiKiKqNt9888bYpJm1QMOGDWPChAmrpU2YMKHWjgbz3XvvvWy22WZrte/8wDFmzBgOOOCAtdpWc1JMiSPfLKCYp3lmA9vkTPfI0laKiHcj4oiIGABckKV9VMe6s7PxWrdpZpbrqKOO4p577lnZ79PMmTN599132WuvvTj99NOpqqpil1124ZJLLim4fq9evfjgg/QKorFjx7LDDjvwla98ZWXX65Ce0dhtt93o168fRx55JIsXL+bJJ5/k7rvv5oc//CH9+/fnjTfeYMSIEdx1110APPTQQwwYMIC+ffty0kkn8dlnn63c3yWXXMLAgQPp27cvr7766hp5qnT368W0cVxFelocUqDpDzxfxLafA7aX1Jt0cT8WOC5v212B+RGxAjgfuCGb9QDw05wG8a8D50fE/OzOri8DzwDHk55qN7MW4JxzYMqUxt1m//5wxRW1z+/cuTODBw/mvvvu49BDD2XChAl8+9vfRhJjx46lc+fOLF++nP3335+pU6ey6667FtzOpEmTmDBhAlOmTGHZsmUMHDiQQYMGAXDEEUdwyimnAHDhhRdy/fXXc9ZZZ3HIIYdw8MEHc9RRR622rSVLljBixAgeeughdthhB44//niuueYazjnnHAC6du3K888/z29/+1suv/xyfv/736+2fqW7Xy+mxFENTMqGp4AfRcR36lspIpYBZ5KCwCvAnRExTdKYnDcK7gtMl/QasCUwNlt3PvATUvB5DhhT01AOnAH8HpgBvIEbxs2sHrnVVbnVVHfeeScDBw5kwIABTJs2bbVqpXyPP/44hx9+OO3bt2eTTTbhkENWvhiVl156ib322ou+ffsyfvx4pk2bVmd+pk+fTu/evdlhh9Rf7AknnMBjj6263+iII1LT76BBg1Z2jJhr6dKlnHLKKfTt25ejjz56Zb6L7X69fX5PkiUq5n0cdwFLImI5pNtsJbWPiHq7YYyIe4F789Iuzhm/K9t+oXVvYFUJJDe9mtTOYmYtTF0lg3I69NBDOffcc3n++edZvHgxgwYN4l//+heXX345zz33HJ06dWLEiBG1dqdenxEjRjBx4kT69evHTTfdxKOPPtqg/NZ0zV5bt+y53a+vWLGiSd/FAUU+OQ60y5luB7T82wLMbL3RoUMH9ttvP0466aSVpY2FCxey8cYbs+mmm/L+++9z3311V17svffeTJw4kU8//ZRFixbx17/+deW8RYsW0a1bN5YuXcr4nPfcduzYkUWLFq2xrR133JGZM2cyY8YMIPVyu88++xR9PJXufr2YwNE293Wx2XjDyjlmZk1s2LBhvPDCCysDR79+/RgwYAB9+vThuOOOY88996xz/YEDB3LMMcfQr18/DjzwQHbbbbeV837yk5+w++67s+eee9KnT5+V6cceeyy//OUvGTBgwGoN0m3btuXGG2/k6KOPpm/fvrRq1YrTTjut6GOpdPfrxXSr/gRwVkQ8n00PAv4nIvZo0J6bkLtVN6scd6veMpTSrXoxbRznAH+U9C7p1bFbkV4la2Zm66F6A0dEPCepD7BjljQ9Igq/yd3MzNZ59bZxSPoesHFEvBQRLwEdJJ1R/qyZmVlzVEzj+CnZ09wARMSHpN5pzcyKUl9bqlVWqX+fYgJH69x3XmTdpbcpMV9mtp5q27Yt8+bNc/BopiKCefPmlfQsSDGN4/cDd0j6XTZ9Kn5a28yK1KNHD2bNmoV7qW6+2rZtS48ePepfMFNM4PgRMBKoucl4KunOKjOzem244Yb07t270tmwRlRMt+orSB0KziS9nOmrpL6nzMxsPVRriUPSDsCwbPgAuAMgIvZrmqyZmVlzVFdV1avA48DBETEDQNK5TZIrMzNrtuqqqjoCmAM8Iuk6SfuTnhw3M7P1WK2BIyImRsSxQB/gEVLXI1tIukbS15sof2Zm1swU0zj+SUTcHhHfIr2qdTLpTiszM1sPlfTO8Yj4MCLGRcT+5cqQmZk1byUFDjMzMwcOMzMriQOHmZmVpKyBQ9JQSdMlzZA0qsD8bSU9ImmypKmSDsrSh0uakjOskNQ/m/dots2aeVuU8xjMzGx1xfRVtVayXnSvBr4GzAKek3R3RLycs9iFwJ0RcY2knYF7gV4RMR4Yn22nLzAxIqbkrDc8IvwuWDOzCihniWMwMCMi3oyIz4EJwKF5ywSwSTa+KfBuge0My9Y1M7NmoJyBozvwTs70rCwt12jgO5JmkUobZxXYzjHAH/LSbsyqqS7KfVdILkkjJVVLqnZ3zmZmjafSjePDgJsiogdwEHCrpJV5krQ7sDh7ZW2N4RHRF9grG75baMPZ8yZVEVG1+eabl+8IzMzWM+UMHLOBbXKme2RpuU4G7gSIiKeAtkDXnPnHklfaiIjZ2eci4HZSlZiZmTWRcgaO54DtJfWW1IYUBO7OW+ZtYH8ASTuRAsfcbLoV8G1y2jckbSCpaza+IXAw8BJmZtZkynZXVUQsk3Qm8ADQGrghIqZJGgNUR8TdwH8C12XdtQcwIla9mHhv4J2IeDNnsxsBD2RBozXwIHBduY7BzMzWpPXhBfJVVVVRXe27d83MSiFpUkRU5adXunHczMxaGAcOMzMriQOHmZmVxIHDzMxK4sBhZmYlceAwM7OSOHCYmVlJHDjMzKwkDhxmZlYSBw4zMyuJA4eZmZXEgcPMzEriwGFmZiVx4DAzs5I4cJiZWUkcOMzMrCQOHGZmVhIHDjMzK4kDh5mZlaSsgUPSUEnTJc2QNKrA/G0lPSJpsqSpkg7K0ntJ+lTSlGy4NmedQZJezLZ5pSSVK///93/wz3/C/Pnl2oOZWcuzQbk2LKk1cDXwNWAW8JykuyPi5ZzFLgTujIhrJO0M3Av0yua9ERH9C2z6GuAU4Jls+aHAfeU4htGj4aGH0nj37rDrrquGvn1hxx2hTZty7NnMrPkqW+AABgMzIuJNAEkTgEOB3MARwCbZ+KbAu3VtUFI3YJOIeDqbvgU4jDIFjltvhalTVw0vvggPPghLl6b5G24IO+2UgkhuQNl6ayhfOcjMrLLKGTi6A+/kTM8Cds9bZjTwd0lnARsDB+TM6y1pMrAQuDAiHs+2OStvm90L7VzSSGAkwLbbbrtWB9CtWxq+8Y1VaUuXwvTpKYjUBJTHHoPx41ct07nzqkCy555wyCHQtu1aZcHMrNkpZ+AoxjDgpoj4laQ9gFslfQmYA2wbEfMkDQImStqllA1HxDhgHEBVVVU0VoY33BC+9KU0DBu2Kv3DD1MwyQ0oN9wAV14Jm22Wlj3xRKiqcmnEzFq2cgaO2cA2OdM9srRcJ5PaKIiIpyS1BbpGxL+Bz7L0SZLeAHbI1u9RzzYrolMn2HvvNNRYsQIeeQRuvDEN11wDu+wCI0bAd74DW21VseyW1YIFqwJohw5w3HGwQaV/ophZo1FEo/0YX33D0gbAa8D+pIv7c8BxETEtZ5n7gDsi4iZJOwEPkaqeugLzI2K5pO2Ax4G+ETFf0rPA2axqHL8qIu6tKy9VVVVRXV3d+AdZggUL4M47UwB56ilo3RoOOiiVQr75zcZtZJ8zByZNSsPChbDtttCz56qhU6fGKfUsWwavvbZ6KWvqVHj77dWX69s3lbz23bfh+1zX5f7tJk1KPz5+/vNUwjVrapImRUTVGunlChzZTg8CrgBaAzdExFhJY4DqiLg7u5PqOqADqaH8vIj4u6QjgTHAUmAFcElE/DXbZhVwE9CO1Ch+VtRzEM0hcOR69VW46Sa45ZZ0oejaNZVARoyAfv1K21b+hWbSJHg3u8VASm0rn366+jodOqweSPKHrbaCVnk3ar///po3Crz8Mnz2WZrfujX06bPqBoGaz+pq+M//hJkz4eij4fLLUyCzNf921dUpDdLfrk8fmDs3/ej48Y/T4Lv4rClVJHA0F80tcNRYtgz+/vdUCvnLX1LD+4ABqRRy3HHQpcvqy9cXJPr0gUGDVg39+6cg8cEH8NZbtQ8ffrj6ftq0gW22SUEEUpCYO3fV/G7dVg8Qu+6a9r3RRoWP89NPU8D42c/S9KhR8MMfQrt2DT6FLUbN3666etXfLj9IDBqU2sDy/3bnnJNuvvjSl+D662Hw4Eoeia1PHDiaYeDINW8e3H57CiKTJ6eL9yGHpDaR558vLkh07Lh2+160qPagsnz5mrcbd+26dvt5++0UMO68MwWlX/8aDj+88W8W+PxzuP/+dLF98cV0Ae7QIZ2f3KFQWn56mzYp8OUPixcXl14TMIoJEnW55x447bT0HTj3XBgzBtq3b9zzZpbPgaOZB45cL7yQAsj48Smg5AaJqqriLjTN2aOPwtlnp4v6/vvDf/93CpANEQFPPgm33ZYC0/z5qcS2116wZEkKjjXDxx+nzyVLGuVw1tCmTSpNtWuX8jBgQGlBojYLF8KPfgTXXgvbbQe//z3st1+jZr3ZmD8/9dywYEGqxvWdiJXhwNGCAkeNpUvTsC7+sly2DH73O7joonRB/N730pP6nTqVtp2XX04B9vbbUztKu3Zw2GEwfDh8/evp9unaLF2agkhNICkUXD7/fFUQaNcu/S1yp/PT27ZN7T3l9M9/wn/8B8yYASNHwi9+AZtuWt59ltucOfD44+mZqMceSz8qatx//+rPUlnTceBogYFjffDBB3DxxSmIdO4MP/0pnHRS3Rffd9+FP/whBYzJk1ND/te+loLFYYetfZVdS7J4cQq0v/pVupnh2mvhW99q3H1EpADaoUPj/+KfOXNVkHjsMXj99ZS+8cbpodm994avfCXdMNK5c2obcqmj6TlwOHA0a1OmpOqrxx+HgQPT7bt77rlq/sKF8L//m6qiHn44XdR22y0Fi2OOWXefialPdXUKtC++mB4y/e//hs03X7ttffpp2t6TT8ITT6TPefPSTQ9bbQVbbpk+88dzpzfeeM3tRqTbtnMDRc0t2506perEmmegBgxY/Zmfm29OweOuu+DII9fuuGztOXA4cDR7EXDHHfCDH8Ds2SkoHHoo/PGP8Ne/pjaJL3whpQ8fDjvsUOkcNw+ffw6XXQY/+QlsskkKusOG1f8Lfc6c1YPE88+v6odtxx1hyJD0OW9euh37vfdWDXPnpr9Xvg4dVg8qEamt4t//TvO33HJVkNhnn9S2lX/rd66amzMgBcdyVwO2dMuWpb9N7t/q6KPXvl3NgcOBo8X45JP00Nsvf5meE9l881Sq+M530q2orrIobNo0OPlkeOYZOPjg1FNBj6yfheXL0/yaIPHEE/Cvf6V5bdum0tuQIamUt8ce9d85t2xZqmbMvUDlB5f3309BbciQVcFi++1L//vddVe6+N18Mxx/fOnnpaVbsSLdLJB/fgud8w8+WDOgv/ji2j9A6sDhwNHivPVWurjtuWfdjdy2yvLlcNVVcMEF6df5SSfBK6/A00+n6j5IJYE991wVKAYMaN4PFq5YkQLb/Pmpg9HmkNelS9OFes6c1OZW85k7PmdOupBLaWjVqvahtvk1JYhly9bMQ00VYqEqw9zxbbZZ+/8fBw4HDluPvPlmuuPq4YdTVU9uoOjVq+WV2u6/Hw48EK6+Gs44o2n2+ckn6W69t99eMyAUqqpr1SpdrLfeOg3duqWSm5SWXbGi7qHQMq1awRZbFA4Mm2xS/r+jA4cDh62HPv+8efxCb6iI1Cby+uvwxhtNc4v6sGEwYULhgJD7WTO+xRbrXhtMbYHDfZaarcPWhaAB6Zf12LGpneTqq1MPBOV0550paIweDRdeuO4FhIZyicPMWowDD4Rnn01VceV66PG999LdXl/4QrqRYH1+JUBtJY46boQzM2teLr00NZL/+tfl2X4EnHJKesDyllvW76BRFwcOM2sxBg2Co45KgSO3x+bGcvPN8Le/pZ6c+/Rp/O2vKxw4zKxFGTMmlQh+/vPG3e7bb8P3v58a4c8+u3G3va5x4DCzFmWnndKDgFdfDbNmNc42V6xID08uX556pq7raXZz4DCzFuiSS9LF/tJLG2d7114LDz6YqsB6926cba7LHDjMrMXp1Ss94Hj99al7+YaYMSPd3vuNb6SGcaufA4eZtUgXXJC60hg9eu23sXx56n23TZsUhFraE/WV4sBhZi1St26pEfv22+Gll9ZuG7/+derw8aqroHv3xs3fuqysgUPSUEnTJc2QNKrA/G0lPSJpsqSpkg7K0r8maZKkF7PPr+as82i2zSnZsEU5j8HMmq/zzksv7rrootLXnTYtPRV++OGpm34rXtkCh6TWwNXAgcDOwDBJO+ctdiFwZ0QMAI4FfpulfwB8KyL6AicAt+atNzwi+mfDv8t1DGbWvHXunN7fMnFieqK8WEuXpjuzNtkkNYy7iqo05SxxDAZmRMSbEfE5MAE4NG+ZADbJxjcF3gWIiMkR8W6WPg1oJ2mjMubVzFqoc85JvdBecEHx6/z0p+nFVb/7Xeqc0EpTzsDRHXgnZ3pWlpZrNPAdSbOAe4GzCmznSOD5iPgsJ+3GrJrqIqnwbwVJIyVVS6qeW45HTM2sWejYEX7843Q77cMP17/8pEnpNt7hw+GII8qfv3VRpRvHhwE3RUQP4CDgVkkr8yRpF+Ay4NScdYZnVVh7ZcN3C204IsZFRFVEVG2+ti9hNrMW4fTT09sOL7ig8CttayxZAieckEoZV13VdPlb15QzcMwGtsmZ7pGl5ToZuBMgIp4C2gJdAST1AP4MHB8Rb9SsEBGzs89FwO2kKjEzW4+1bZsayJ9+OvU1VZtLLkmN4tdfD506NV3+1jXlDBzPAdtL6i2pDanx++68Zd4G9geQtBMpcMyVtBlwDzAqIp6oWVjSBpJqAsuGwMHAWt6IZ2brkhNPTF2hX3hheqo835NPpvfYjxwJQ4c2ff7WJWULHBGxDDgTeAB4hXT31DRJYyQdki32n8Apkl4A/gCMiPSCkDOBLwIX5912uxHwgKSpwBRSCea6ch2DmbUcG26YOkCcOjW9iCnXJ5+ku6h69oTLL69M/tYlfpGTma0zVqyA/v3h00/h5ZdTMAE488zUKeKjj6beb604fpGTma3zWrVKd0zNmJHerQHpbqurr0637TpoNA6XOMxsnRIBX/4yvPtuuvW2qgrat4fJk6Fdu0rnrmVxicPM1gtSesBv1iwYPBhmz06lDweNxuPAYWbrnP33h69+Fd56C0aNgt13r3SO1i1+FbuZrZOuvTaVNNamA0SrmwOHma2Ttt++8d4QaKtzVZWZmZXEgcPMzEriwGFmZiVx4DAzs5I4cJiZWUkcOMzMrCQOHGZmVhIHDjMzK8l60cmhpLnAW5XORy26Ah9UOhN1cP4axvlrGOevYRqav54Rsca7t9eLwNGcSaou1Ptkc+H8NYzz1zDOX8OUK3+uqjIzs5I4cJiZWUkcOCpvXKUzUA/nr2Gcv4Zx/hqmLPlzG4eZmZXEJQ4zMyuJA4eZmZXEgaMJSNpG0iOSXpY0TdL3Cyyzr6QFkqZkw8VNnMeZkl7M9l1dYL4kXSlphqSpkgY2Yd52zDkvUyQtlHRO3jJNev4k3SDp35JeyknrLOkfkl7PPjvVsu4J2TKvSzqhCfP3S0mvZn+/P0varJZ16/wulDF/oyXNzvkbHlTLukMlTc++i6OaMH935ORtpqQptazbFOev4DWlyb6DEeGhzAPQDRiYjXcEXgN2zltmX+BvFczjTKBrHfMPAu4DBHwZeKZC+WwNvEd6MKli5w/YGxgIvJST9gtgVDY+CriswHqdgTezz07ZeKcmyt/XgQ2y8csK5a+Y70IZ8zca+EERf/83gO2ANsAL+f9L5cpf3vxfARdX8PwVvKY01XfQJY4mEBFzIuL5bHwR8ArQvbK5KtmhwC2RPA1sJqlbBfKxP/BGRFS0J4CIeAyYn5d8KHBzNn4zcFiBVb8B/CMi5kfEh8A/gKFNkb+I+HtELMsmnwZ6NPZ+i1XL+SvGYGBGRLwZEZ8DE0jnvVHVlT9JAr4N/KGx91usOq4pTfIddOBoYpJ6AQOAZwrM3kPSC5Luk7RL0+aMAP4uaZKkkQXmdwfeyZmeRWWC37HU/g9byfMHsGVEzMnG3wO2LLBMczmPJ5FKkIXU910opzOzqrQbaqlmaQ7nby/g/Yh4vZb5TXr+8q4pTfIddOBoQpI6AH8CzomIhXmznydVv/QDrgImNnH2vhIRA4EDge9J2ruJ918vSW2AQ4A/Fphd6fO3mkh1As3yXndJFwDLgPG1LFKp78I1wBeA/sAcUnVQczSMuksbTXb+6rqmlPM76MDRRCRtSPoDj4+I/82fHxELI+LjbPxeYENJXZsqfxExO/v8N/BnUpVArtnANjnTPbK0pnQg8HxEvJ8/o9LnL/N+TfVd9vnvAstU9DxKGgEcDAzPLixrKOK7UBYR8X5ELI+IFcB1tey30udvA+AI4I7almmq81fLNaVJvoMOHE0gqxO9HnglIn5dyzJbZcshaTDpbzOvifK3saSONeOkRtSX8ha7GzheyZeBBTlF4qZS6y+9Sp6/HHcDNXeonAD8pcAyDwBfl9Qpq4r5epZWdpKGAucBh0TE4lqWKea7UK785baZHV7Lfp8DtpfUOyuBHks6703lAODViJhVaGZTnb86rilN8x0sZ8u/h5V3MXyFVGScCkzJhoOA04DTsmXOBKaR7hJ5GhjShPnbLtvvC1keLsjSc/Mn4GrSHS0vAlVNfA43JgWCTXPSKnb+SAFsDrCUVEd8MtAFeAh4HXgQ6JwtWwX8Pmfdk4AZ2XBiE+ZvBqluu+Y7eG227NbAvXV9F5oof7dm362ppAtgt/z8ZdMHke4ieqMp85el31TznctZthLnr7ZrSpN8B93liJmZlcRVVWZmVhIHDjMzK4kDh5mZlcSBw8zMSuLAYWZmJXHgMFtLkpZr9V57G62nVkm9cntmNWtONqh0BsxasE8jon+lM2HW1FziMGtk2fsYfpG9k+FZSV/M0ntJejjrxO8hSdtm6VsqvR/jhWwYkm2qtaTrsvct/F1Su2z5s7P3MEyVNKFCh2nrMQcOs7XXLq+q6piceQsioi/wP8AVWdpVwM0RsSupg8Ers/QrgX9G6qBxIOmJY4DtgasjYhfgI+DILH0UMCDbzmnlOTSz2vnJcbO1JOnjiOhQIH0m8NWIeDPriO69iOgi6QNSNxpLs/Q5EdFV0lygR0R8lrONXqR3JmyfTf8I2DAiLpV0P/AxqQfgiZF17mjWVFziMCuPqGW8FJ/ljC9nVZvkN0n9hg0Enst6bDVrMg4cZuVxTM7nU9n4k6TeXAGGA49n4w8BpwNIai1p09o2KqkVsE1EPAL8CNgUWKPUY1ZO/qVitvbaSZqSM31/RNTckttJ0lRSqWFYlnYWcKOkHwJzgROz9O8D4ySdTCpZnE7qmbWQ1sBtWXARcGVEfNRIx2NWFLdxmDWyrI2jKiI+qHRezMrBVVVmZlYSlzjMzKwkLnGYmVlJHDjMzKwkDhxmZlYSBw4zMyuJA4eZmZXk/wN0G12DXsvpngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-nurse",
   "metadata": {},
   "source": [
    "### 4-2) CNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acquired-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, None, 5)           405       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, None, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, None, 5)           130       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,592\n",
      "Trainable params: 160,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6877 - val_accuracy: 0.5658\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.6833 - accuracy: 0.6494 - val_loss: 0.6450 - val_accuracy: 0.7938\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.6109 - accuracy: 0.7996 - val_loss: 0.4338 - val_accuracy: 0.8617\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.3883 - accuracy: 0.8638 - val_loss: 0.2606 - val_accuracy: 0.9123\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2553 - accuracy: 0.9080 - val_loss: 0.1874 - val_accuracy: 0.9428\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1843 - accuracy: 0.9395 - val_loss: 0.1362 - val_accuracy: 0.9624\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.1373 - accuracy: 0.9601 - val_loss: 0.0996 - val_accuracy: 0.9773\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0998 - accuracy: 0.9750 - val_loss: 0.0736 - val_accuracy: 0.9863\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0752 - accuracy: 0.9849 - val_loss: 0.0537 - val_accuracy: 0.9920\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0551 - accuracy: 0.9910 - val_loss: 0.0385 - val_accuracy: 0.9954\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0378 - accuracy: 0.9954 - val_loss: 0.0287 - val_accuracy: 0.9970\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0274 - accuracy: 0.9971 - val_loss: 0.0222 - val_accuracy: 0.9981\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0206 - accuracy: 0.9985 - val_loss: 0.0176 - val_accuracy: 0.9986\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 0.0151 - val_accuracy: 0.9988\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9989 - val_loss: 0.0126 - val_accuracy: 0.9989\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.0104 - val_accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.0091 - val_accuracy: 0.9991\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9995\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 49157\n  y sizes: 25000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6eefeed7d6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     verbose=1)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 49157\n  y sizes: 25000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(5, 5, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(5, 5, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "results = model.evaluate(X_test,  y_test, verbose=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-shade",
   "metadata": {},
   "source": [
    "### 4-3) CNN 모델 /w 다른 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "friendly-budapest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, None, 3)           147       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, None, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, None, 3)           30        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,218\n",
      "Trainable params: 160,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "49/49 [==============================] - 6s 79ms/step - loss: 0.6929 - accuracy: 0.5212 - val_loss: 0.6891 - val_accuracy: 0.6039\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.6855 - accuracy: 0.6149 - val_loss: 0.6623 - val_accuracy: 0.6912\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.6471 - accuracy: 0.7122 - val_loss: 0.5919 - val_accuracy: 0.7822\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.5728 - accuracy: 0.7845 - val_loss: 0.5021 - val_accuracy: 0.8215\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.4785 - accuracy: 0.8271 - val_loss: 0.4029 - val_accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.3885 - accuracy: 0.8648 - val_loss: 0.3256 - val_accuracy: 0.8894\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.3198 - accuracy: 0.8886 - val_loss: 0.2685 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.2659 - accuracy: 0.9087 - val_loss: 0.2262 - val_accuracy: 0.9298\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2241 - accuracy: 0.9280 - val_loss: 0.1947 - val_accuracy: 0.9430\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1907 - accuracy: 0.9415 - val_loss: 0.1642 - val_accuracy: 0.9549\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1636 - accuracy: 0.9531 - val_loss: 0.1400 - val_accuracy: 0.9646\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1385 - accuracy: 0.9622 - val_loss: 0.1195 - val_accuracy: 0.9707\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.1212 - accuracy: 0.9695 - val_loss: 0.1029 - val_accuracy: 0.9769\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.1023 - accuracy: 0.9759 - val_loss: 0.0881 - val_accuracy: 0.9823\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.0872 - accuracy: 0.9805 - val_loss: 0.0752 - val_accuracy: 0.9856\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.0723 - accuracy: 0.9855 - val_loss: 0.0650 - val_accuracy: 0.9888\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0617 - accuracy: 0.9892 - val_loss: 0.0567 - val_accuracy: 0.9905\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0545 - accuracy: 0.9904 - val_loss: 0.0487 - val_accuracy: 0.9926\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0482 - accuracy: 0.9923 - val_loss: 0.0422 - val_accuracy: 0.9944\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0402 - accuracy: 0.9940 - val_loss: 0.0371 - val_accuracy: 0.9955\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 49157\n  y sizes: 25000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ff13d283f8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     verbose=1)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 49157\n  y sizes: 25000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(3, 3, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(3, 3, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-scale",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "commercial-dodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-prisoner",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dutch-prompt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "measured-disclosure",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-823fadcb02b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'computer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-baghdad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-marshall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
